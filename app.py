import io
import streamlit as st
from PyPDF2 import PdfReader
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lex_rank import LexRankSummarizer

st.set_page_config(page_title="PDF ì¶”ì¶œì  ìš”ì•½ (ë¬´ë£Œ)", layout="wide")
st.title("ğŸ“„ PDF ì—…ë¡œë“œ â†’ ì¶”ì¶œì  ìš”ì•½ (ë¬´ë£Œ)")

# ì‚¬ì´ë“œë°”: ìš”ì•½ ë¬¸ì¥ ìˆ˜ ì„ íƒ
num_sentences = st.sidebar.slider("ìš”ì•½ ë¬¸ì¥ ìˆ˜", 1, 10, 5)

# PDF ì—…ë¡œë“œ
uploaded = st.file_uploader("PDF íŒŒì¼ ì˜¬ë¦¬ê¸°", type="pdf")
if not uploaded:
    st.info("ì¢Œì¸¡ì—ì„œ PDFë¥¼ ì˜¬ë ¤ ì£¼ì„¸ìš”.")
    st.stop()

# í…ìŠ¤íŠ¸ ì¶”ì¶œ
reader = PdfReader(io.BytesIO(uploaded.read()))
full_text = []
for page in reader.pages:
    txt = page.extract_text()
    if txt:
        full_text.append(txt)
doc = "\n".join(full_text)

if not doc.strip():
    st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ì¶”ì¶œì  ìš”ì•½
parser = PlaintextParser.from_string(doc, Tokenizer("korean"))
summarizer = LexRankSummarizer()
summary_sentences = summarizer(parser.document, num_sentences)
summary = "\n".join(str(s).strip() for s in summary_sentences)

# ê²°ê³¼ ì¶œë ¥
st.subheader("ğŸ” ì¶”ì¶œì  ìš”ì•½ ê²°ê³¼")
st.write(summary)

with st.expander("ì›ë¬¸ ì¼ë¶€ ë³´ê¸°"):
    st.write(doc[:2000] + "â€¦")
