# app.py

import io, json, base64, streamlit as st
from PyPDF2 import PdfReader
from google.cloud import storage, aiplatform_v1
from google.oauth2 import service_account
import google.generativeai as genai
from tenacity import retry, stop_after_attempt, wait_exponential

# â”€â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="PDF ìš”ì•½ & ëª¨ë¸ ì¡°íšŒ", layout="wide")
st.title("ğŸ“„ PDF ìš”ì•½ & Generative AI ëª¨ë¸ ì¡°íšŒ")

# â”€â”€â”€ ì‹œí¬ë¦¿ ë¡œë“œ & GCS ì¸ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
gcs_b64     = st.secrets["GCS_SA_KEY_B64"]
gcs_info    = json.loads(base64.b64decode(gcs_b64))
bucket_name = st.secrets["GCS_BUCKET_NAME"]

gcs_creds   = service_account.Credentials.from_service_account_info(gcs_info)
gcs_client  = storage.Client(credentials=gcs_creds, project=gcs_info["project_id"])
bucket      = gcs_client.bucket(bucket_name)

# â”€â”€â”€ Generative AI ì¸ì¦ & í´ë¼ì´ì–¸íŠ¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
genai_b64   = st.secrets["GENAI_SA_KEY_B64"]
genai_info  = json.loads(base64.b64decode(genai_b64))
genai_creds = service_account.Credentials.from_service_account_info(genai_info)
genai.configure(api_key=None, credentials=genai_creds)

# Vertex AI Prediction í´ë¼ì´ì–¸íŠ¸ (text-bison ì‚¬ìš© ì‹œ)
prediction_client = aiplatform_v1.PredictionServiceClient(credentials=genai_creds)
project_id = genai_info["project_id"]
location   = "us-central1"

# â”€â”€â”€ 1) ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("1ï¸âƒ£ ì‚¬ìš© ê°€ëŠ¥í•œ Generative AI ëª¨ë¸")
models = genai.list_models()
model_names = [m.name for m in models]
selected_model = st.selectbox("ëª¨ë¸ ì„ íƒ", model_names)

# ë§Œì•½ text-bison ê³„ì—´ì„ ì„ íƒí–ˆë‹¤ë©´ PredictionServiceClient ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ endpoint êµ¬ì„±
use_prediction = selected_model.startswith("text-") or selected_model.startswith("bison")
if use_prediction:
    endpoint = f"projects/{project_id}/locations/{location}/publishers/google/models/{selected_model}"

# â”€â”€â”€ GCS PDF ëª©ë¡ / ì—…ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("2ï¸âƒ£ PDF ì—…ë¡œë“œ & ëª©ë¡")
uploaded = st.file_uploader("ìƒˆ PDF ì—…ë¡œë“œ", type="pdf")
if uploaded:
    blob = bucket.blob(f"pdfs/{uploaded.name}")
    blob.upload_from_file(io.BytesIO(uploaded.read()), content_type="application/pdf")
    st.success(f"âœ… GCSì— ì €ì¥ë¨: {uploaded.name}")

def list_pdfs():
    return [b.name.split("/",1)[1] for b in gcs_client.list_blobs(bucket_name, prefix="pdfs/") if b.name.endswith(".pdf")]

pdfs = list_pdfs()
selected_pdf = st.selectbox("ìš”ì•½í•  PDF ì„ íƒ", pdfs)

# â”€â”€â”€ 3) ìš”ì•½ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("3ï¸âƒ£ ì„ íƒí•œ PDF 3ì¤„ ìš”ì•½")
if st.button("ìš”ì•½ ì‹œì‘"):
    pdf_bytes = bucket.blob(f"pdfs/{selected_pdf}").download_as_bytes()
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
    reader = PdfReader(io.BytesIO(pdf_bytes))
    txt = "".join(p.extract_text() or "" for p in reader.pages)[:1000]
    if not txt.strip():
        st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        prompt = "ë‹¤ìŒ ë‚´ìš©ì„ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\n\n" + txt

        @retry(reraise=True, stop=stop_after_attempt(4), wait=wait_exponential(min=1, max=5))
        def summarize(prompt: str) -> str:
            if use_prediction:
                res = prediction_client.predict(
                    endpoint=endpoint,
                    instances=[{"content": prompt}],
                    parameters={"temperature":0.3, "maxOutputTokens":256},
                )
                return res.predictions[0].get("content","").strip()
            else:
                # í…ìŠ¤íŠ¸ ìƒì„± API
                resp = genai.text.completions.create(
                    model=selected_model,
                    prompt=prompt,
                    temperature=0.3,
                    max_output_tokens=256,
                )
                return resp.choices[0].text.strip()

        with st.spinner("ìš”ì•½ ìƒì„± ì¤‘â€¦"):
            try:
                summary = summarize(prompt)
                st.text_area("ğŸ“ ìš”ì•½ ê²°ê³¼", summary, height=200)
            except Exception as e:
                st.error(f"ìš”ì•½ ì‹¤íŒ¨: {e}")
